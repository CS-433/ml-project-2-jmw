{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df335dde-8a74-4e98-84b4-44fb3f3dbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from Config import Config\n",
    "from Models import PreTrainedKPD, PreTrainedConf, Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cb2e4f9-82ff-4a46-ae18-f4335d533d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wene/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/wene/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_58269/923896920.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  kpd_model.load_state_dict(torch.load(\"Models/Saves/pretrainedKPD_weights00166.pth\", map_location=device))\n",
      "/tmp/ipykernel_58269/923896920.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  conf_model.load_state_dict(torch.load(\"Models/Saves/pretrainedConf_weights00166.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the model weights.\n",
    "\"\"\"\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "kpd_model = PreTrainedKPD.KeypointDetectionModel().to(device)\n",
    "kpd_model.load_state_dict(torch.load(\"Models/Saves/pretrainedKPD_weights00166.pth\", map_location=device))\n",
    "\n",
    "conf_model = PreTrainedConf.ConfidenceModel().to(device)\n",
    "conf_model.load_state_dict(torch.load(\"Models/Saves/pretrainedConf_weights00166.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd7ca65d-3e6b-45d3-98af-a8b22f6fb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_csv('CSVs/combined.csv')\n",
    "preds = pd.read_csv('predictions_17december.csv')\n",
    "\n",
    "preds['Image Name'] = preds['Image Name'].map(lambda s : os.path.splitext(s)[0])\n",
    "notes['Image Name'] = notes['Image Name'].map(lambda s : os.path.splitext(s)[0])\n",
    "\n",
    "notes = notes.groupby(['Image Name']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03dc0b7b-1184-4baf-bdec-e7047334edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_predicted</th>\n",
       "      <th>y1_predicted</th>\n",
       "      <th>x2_predicted</th>\n",
       "      <th>y2_predicted</th>\n",
       "      <th>Error estimate</th>\n",
       "      <th>x1_real</th>\n",
       "      <th>y1_real</th>\n",
       "      <th>x2_real</th>\n",
       "      <th>y2_real</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antweb1038578_p_1</th>\n",
       "      <td>968.425214</td>\n",
       "      <td>278.650289</td>\n",
       "      <td>888.545968</td>\n",
       "      <td>303.143567</td>\n",
       "      <td>0.342074</td>\n",
       "      <td>703.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0003131_p_1</th>\n",
       "      <td>732.926435</td>\n",
       "      <td>206.051771</td>\n",
       "      <td>500.225782</td>\n",
       "      <td>190.303367</td>\n",
       "      <td>0.138038</td>\n",
       "      <td>349.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0217464_p_1</th>\n",
       "      <td>760.971606</td>\n",
       "      <td>264.559571</td>\n",
       "      <td>366.700752</td>\n",
       "      <td>164.620090</td>\n",
       "      <td>0.271314</td>\n",
       "      <td>407.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0103447_p_1</th>\n",
       "      <td>655.816242</td>\n",
       "      <td>194.425754</td>\n",
       "      <td>449.774630</td>\n",
       "      <td>201.630753</td>\n",
       "      <td>0.329780</td>\n",
       "      <td>270.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0249764_p_1</th>\n",
       "      <td>601.015129</td>\n",
       "      <td>234.377738</td>\n",
       "      <td>373.912095</td>\n",
       "      <td>196.411209</td>\n",
       "      <td>0.390359</td>\n",
       "      <td>359.5</td>\n",
       "      <td>241.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>310.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0907340_p_1</th>\n",
       "      <td>671.910096</td>\n",
       "      <td>177.615879</td>\n",
       "      <td>482.972262</td>\n",
       "      <td>203.188506</td>\n",
       "      <td>0.322776</td>\n",
       "      <td>227.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0913305_p_1</th>\n",
       "      <td>675.294641</td>\n",
       "      <td>236.662282</td>\n",
       "      <td>341.467381</td>\n",
       "      <td>128.393289</td>\n",
       "      <td>0.372602</td>\n",
       "      <td>299.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0178037_p_1</th>\n",
       "      <td>557.770351</td>\n",
       "      <td>209.588442</td>\n",
       "      <td>320.066273</td>\n",
       "      <td>187.612372</td>\n",
       "      <td>0.262641</td>\n",
       "      <td>253.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0900316_p_1</th>\n",
       "      <td>568.744066</td>\n",
       "      <td>226.550829</td>\n",
       "      <td>318.352319</td>\n",
       "      <td>137.751487</td>\n",
       "      <td>0.196751</td>\n",
       "      <td>284.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casent0235352_p_1</th>\n",
       "      <td>727.688009</td>\n",
       "      <td>257.846809</td>\n",
       "      <td>391.151309</td>\n",
       "      <td>143.265749</td>\n",
       "      <td>0.261686</td>\n",
       "      <td>464.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x1_predicted  y1_predicted  x2_predicted  y2_predicted  \\\n",
       "Image Name                                                                  \n",
       "antweb1038578_p_1    968.425214    278.650289    888.545968    303.143567   \n",
       "casent0003131_p_1    732.926435    206.051771    500.225782    190.303367   \n",
       "casent0217464_p_1    760.971606    264.559571    366.700752    164.620090   \n",
       "casent0103447_p_1    655.816242    194.425754    449.774630    201.630753   \n",
       "casent0249764_p_1    601.015129    234.377738    373.912095    196.411209   \n",
       "...                         ...           ...           ...           ...   \n",
       "casent0907340_p_1    671.910096    177.615879    482.972262    203.188506   \n",
       "casent0913305_p_1    675.294641    236.662282    341.467381    128.393289   \n",
       "casent0178037_p_1    557.770351    209.588442    320.066273    187.612372   \n",
       "casent0900316_p_1    568.744066    226.550829    318.352319    137.751487   \n",
       "casent0235352_p_1    727.688009    257.846809    391.151309    143.265749   \n",
       "\n",
       "                   Error estimate  x1_real  y1_real  x2_real  y2_real  \n",
       "Image Name                                                             \n",
       "antweb1038578_p_1        0.342074    703.0    334.0   1130.0    426.0  \n",
       "casent0003131_p_1        0.138038    349.0    223.0    784.0    241.0  \n",
       "casent0217464_p_1        0.271314    407.0    128.0    751.0    253.0  \n",
       "casent0103447_p_1        0.329780    270.0    216.0    628.0    313.0  \n",
       "casent0249764_p_1        0.390359    359.5    241.0    641.0    310.5  \n",
       "...                           ...      ...      ...      ...      ...  \n",
       "casent0907340_p_1        0.322776    227.0    205.0    849.0    356.0  \n",
       "casent0913305_p_1        0.372602    299.0    121.0    704.0    267.0  \n",
       "casent0178037_p_1        0.262641    253.0    186.0    575.0    247.0  \n",
       "casent0900316_p_1        0.196751    284.0    120.0    627.0    293.0  \n",
       "casent0235352_p_1        0.261686    464.0    116.0    775.0    276.0  \n",
       "\n",
       "[3636 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.set_index('Image Name').join(notes, how='inner', lsuffix='_predicted', rsuffix='_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e838b08-5fa5-4892-84f1-daaea59ef7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_shape(file_path):\n",
    "    with Image.open(file_path) as img:\n",
    "        return img.size\n",
    "\n",
    "\n",
    "notes['shape'] = notes.index.map(lambda s : get_image_shape(\n",
    "    os.path.join(Config.images_folder_path, s + '.png')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25c122c7-9706-466b-96a0-ceda6b124988",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m errors \u001b[38;5;241m=\u001b[39m (keypoints \u001b[38;5;241m-\u001b[39m outputs)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      2\u001b[0m mse_per_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(errors, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m mse_per_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(mse_per_vector, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mclamp_threshold)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "errors = (keypoints - outputs)**2\n",
    "mse_per_vector = torch.mean(errors, dim=1, keepdim=True)\n",
    "\n",
    "mse_per_vector = torch.clamp(mse_per_vector, max=clamp_threshold)\n",
    "mse_per_vector_np = mse_per_vector.cpu().numpy()\n",
    "\n",
    "# Step 1: Normalize by mean and variance\n",
    "mean = mse_per_vector.mean()\n",
    "std = mse_per_vector.std()\n",
    "normalized_vector = (mse_per_vector - mean) / std\n",
    "\n",
    "# Step 2: Scale to range [0, 1]\n",
    "min_val = normalized_vector.min()\n",
    "max_val = normalized_vector.max()\n",
    "scaled_errors = (normalized_vector - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e1dce-4145-4cf8-8ac0-8535a0ed44ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
